Awesome Pipeline
================

A curated list of awesome pipeline toolkits inspired by [Awesome Sysadmin](https://github.com/kahun/awesome-sysadmin)

Pipeline frameworks & libraries
--------------------------------

* [ActionChain](http://docs.stackstorm.com/actionchain.html) - A workflow system for simple linear success/failure workflows.
* [Airflow](https://github.com/airbnb/airflow) - Python-based workflow system created by AirBnb.
* [Anduril](http://www.anduril.org/anduril/site/) - Component-based workflow framework for scientific data analysis.
* [Antha](https://www.antha-lang.org/) - High-level language for biology.
* [Bds](http://pcingola.github.io/BigDataScript/) - Scripting language for data pipelines.
* [Bpipe](https://github.com/ssadedin/bpipe/) - Tool for running and managing bioinformatics pipelines.
* [Chipster](http://chipster.csc.fi/) - Platform for data analysis, with workflow and visualization built-in.
* [Cluster flow](http://ewels.github.io/clusterflow/) - Command-line tool which uses common cluster managers to run bioinformatics pipelines.
* [Compss](http://www.bsc.es/computer-sciences/grid-computing/comp-superscalar) - Programming model for distributed infrastructures.
* [Conan2](https://github.com/tburdett/Conan2) - Light-weight workflow management application.
* [Cosmos](https://cosmos.hms.harvard.edu) - Python library for massively parallel workflows.
* [Joblib](https://pythonhosted.org/joblib/index.html) - Set of tools to provide lightweight pipelining in Python.
* [Luigi](https://github.com/spotify/luigi) - Python module that helps you build complex pipelines of batch jobs.
* [Makeflow](http://ccl.cse.nd.edu/software/makeflow/) - Workflow engine for executing large complex workflows on clusters.
* [Mistral](https://github.com/openstack/mistral) - Python based workflow engine by the Open Stack project.
* [Moa](https://github.com/mfiers/Moa) - Lightweight workflows in bioinformatics.
* [Nextflow](http://www.nextflow.io) - Flow-based computational toolkit for reproducibile and scalable bioinformatics pipelines.
* [NiPype](https://github.com/nipy/nipype) - Workflows and interfaces for neuroimaging packages.
* [OpenGE](https://github.com/adaptivegenome/openge) - Accelerated framework for manipulating and interpreting high-throughput sequencing data.
* [PipEngine](https://github.com/fstrozzi/bioruby-pipengine) Ruby based launcher for complex biological pipelines.
* [Pinball](https://github.com/pinterest/pinball) - Python based workflow engine by Pinterest.
* [PyFlow](https://github.com/Illumina/pyflow) - Lightweight parallel task engine.
* [Pwrake](https://github.com/masa16/Pwrake/) - Parallel workflow extension for Rake
* [Rabix](https://github.com/rabix/rabix) - Python-based workflow toolkit based on the Common Workflow Language and Docker.
* [Rmake](http://physiology.med.cornell.edu/faculty/mason/lab/r-make/) - Wrapper for the creation of Makefiles, enabling massive parallelization.
* [Rubra](https://github.com/bjpop/rubra) - Pipeline system for bioinformatics workflows.
* [Ruffus](http://www.ruffus.org.uk) - Computation Pipeline library for Python.
* [Sake](http://tonyfischetti.github.io/sake/) - Self-documenting build automation tool.
* [Scoop](https://github.com/soravux/scoop/) - Scalable Concurrent Operations in Python.
* [Snakemake](https://bitbucket.org/johanneskoester/snakemake/wiki/Home) - Tool for running and managing bioinformatics pipelines.
* [Swift](http://swift-lang.org) - Fast easy parallel scripting - on multicores, clusters, clouds and supercomputers.
* [Yap](http://opensource.nibr.com/yap/) - Extensible parallel framework, written in Python using OpenMPI libraries.
* [WorldMake](http://worldmake.org/) - Easy Collaborative Reproducible Computing.
 
Workflow platforms 
--------------------
* [ActivePapers](http://www.activepapers.org/) - Computational science made reproducible and publishable.
* [Biokepler](http://www.biokepler.org) - Bioinformatics Scientific Workflow for Distributed Analysis of Large-Scale Biological Data.
* [Chipster](http://chipster.csc.fi) - Open source platform for data analysis. 
* [Galaxy](https://usegalaxy.org) - Web-based platform for biomedical research.
* [Pegasus](http://pegasus.isi.edu) - Workflow Management System
* [Yabi](http://ccg.murdoch.edu.au/yabi) - Online research environment for grid, HPC and cloud computing.
* [Taverna](http://www.taverna.org.uk) - Domain independent workflow system.
* [VisTrails](http://www.vistrails.org/) - Scientific workflow and provenance management system.
* [Wings](http://www.wings-workflows.org) - Semantic workflow system utilizing Pegasus as execution system.

Workflow languages 
-------------------
* [Common Workflow Language](https://github.com/common-workflow-language/common-workflow-language)
* [Cloudgene Workflow Language](http://cloudgene.uibk.ac.at/developer-guide)
* [Workflow Definition Language](https://github.com/broadinstitute/wdl)
* [Yet Another Workflow Language](http://www.yawlfoundation.org)

Workflow standardization initiatives
---------------------------
* [Workflow 4 Ever Initiative](http://www.wf4ever-project.org)
* [Workflow 4 Ever workflow research object model](http://wf4ever.github.io/ro)
* [Workflow Patterns Initiative](http://www.workflowpatterns.com)
* [Workflow Patterns Library](http://www.workflowpatterns.com/patterns)
* [ResearchObject.org](http://www.researchobject.org)

Literate programming (aka interactive notebooks) 
---------------------------------------------------
* [Beaker](http://beakernotebook.com/) Notebook-style development environment. 
* [IPython](https://ipython.org/) A rich architecture for interactive computing.
* [Jupyter](https://jupyter.org/) Language-agnostic notebook literate programming environment.
* [Pathomx](http://pathomx.org) - Interactive data workflows built on Python.
* [Wakari](https://wakari.io/) - Web-based Python Data Analysis.
* [Zeppelin](http://zeppelin-project.org/) - Web-based notebook that enables interactive data analytics.



